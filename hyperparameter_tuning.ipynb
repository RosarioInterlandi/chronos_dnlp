{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparameter tuning for fine-tuned Chronos-2 models\n",
        "\n",
        "Questo notebook avvia l'iper-tuning partendo da checkpoint **gi\u00e0 finetunati**.\n",
        "I checkpoint si trovano nella cartella `outputs/chronos2_sft` (generale e per categorie).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure project root is on sys.path when running from notebooks/\n",
        "ROOT = Path('..').resolve()\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "if str(ROOT / 'model') not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT / 'model'))\n",
        "\n",
        "import torch\n",
        "\n",
        "from chronos import Chronos2Pipeline\n",
        "from core.data import GICS_LEVEL_1, create_multivariate_windows, prepare_data_for_chronos\n",
        "from core.eval import evaluate_model_on_test\n",
        "from tiingo_data.download_data import get_daily_returns_data_cached\n",
        "from utils import create_train_val_split, get_device\n",
        "\n",
        "# Example: create a JSON mapping for category models\n",
        "category_models = {\n",
        "    'Information Technology': 'outputs/chronos2_sft/categories/Information_Technology/finetuned-ckpt',\n",
        "    'Health Care': 'outputs/chronos2_sft/categories/Health_Care/finetuned-ckpt',\n",
        "}\n",
        "Path('category_models.json').write_text(json.dumps(category_models, indent=2), encoding='utf-8')\n",
        "print('Wrote category_models.json')\n",
        "\n",
        "# Config\n",
        "context_length = 200\n",
        "prediction_length = 1\n",
        "stride = 50\n",
        "min_past = 200\n",
        "test_size = 1200\n",
        "val_ratio = 0.2\n",
        "n_samples = 100\n",
        "seed = 42\n",
        "\n",
        "grid = {\n",
        "    'learning_rate': [1e-6, 5e-6, 1e-5],\n",
        "    'num_steps': [500, 1000],\n",
        "    'batch_size': [16, 32],\n",
        "}\n",
        "\n",
        "# Data prep\n",
        "torch.manual_seed(seed)\n",
        "df_all = get_daily_returns_data_cached()\n",
        "df_train_clean, _ = prepare_data_for_chronos(df_all, test_size=test_size)\n",
        "df_train_split, df_val_split = create_train_val_split(df_train_clean, val_ratio=val_ratio)\n",
        "\n",
        "def build_inputs(df_train, df_val):\n",
        "    train_inputs = create_multivariate_windows(\n",
        "        df_train,\n",
        "        context_length=context_length,\n",
        "        prediction_length=prediction_length,\n",
        "        stride=stride,\n",
        "    )\n",
        "    val_inputs = create_multivariate_windows(\n",
        "        df_val,\n",
        "        context_length=context_length,\n",
        "        prediction_length=prediction_length,\n",
        "        stride=stride,\n",
        "    )\n",
        "    return train_inputs, val_inputs\n",
        "\n",
        "def tune_model(model_path, train_inputs, val_inputs, df_val):\n",
        "    results = []\n",
        "    device = get_device()\n",
        "    for lr in grid['learning_rate']:\n",
        "        for steps in grid['num_steps']:\n",
        "            for batch_size in grid['batch_size']:\n",
        "                print(f'Tuning: lr={lr}, steps={steps}, batch={batch_size}')\n",
        "                pipeline = Chronos2Pipeline.from_pretrained(\n",
        "                    model_path,\n",
        "                    device_map=device,\n",
        "                    dtype=torch.float32,\n",
        "                )\n",
        "                finetuned = pipeline.fit(\n",
        "                    inputs=train_inputs,\n",
        "                    validation_inputs=val_inputs,\n",
        "                    prediction_length=prediction_length,\n",
        "                    context_length=context_length,\n",
        "                    min_past=min_past,\n",
        "                    num_steps=steps,\n",
        "                    batch_size=batch_size,\n",
        "                    learning_rate=lr,\n",
        "                    output_dir=ROOT / 'outputs' / 'hyperparameter_tuning',\n",
        "                )\n",
        "                metrics = evaluate_model_on_test(\n",
        "                    pipeline=finetuned,\n",
        "                    df_test=df_val,\n",
        "                    context_length=context_length,\n",
        "                    n_samples=n_samples,\n",
        "                )\n",
        "                results.append({\n",
        "                    'config': {'learning_rate': lr, 'num_steps': steps, 'batch_size': batch_size},\n",
        "                    'metrics': metrics,\n",
        "                })\n",
        "    return results\n",
        "\n",
        "def top_k(results, k=3):\n",
        "    return sorted(results, key=lambda x: x['metrics']['mean_quantile_loss'])[:k]\n",
        "\n",
        "# General model tuning\n",
        "general_model_path = 'outputs/chronos2_sft/finetuned-ckpt'\n",
        "train_inputs, val_inputs = build_inputs(df_train_split, df_val_split)\n",
        "general_results = tune_model(general_model_path, train_inputs, val_inputs, df_val_split)\n",
        "top_general = top_k(general_results, k=3)\n",
        "\n",
        "# Category models tuning\n",
        "top_categories = {}\n",
        "for category, tickers in GICS_LEVEL_1.items():\n",
        "    model_path = category_models.get(category)\n",
        "    if not model_path:\n",
        "        continue\n",
        "    available = [t for t in tickers if t in df_train_split.columns]\n",
        "    if not available:\n",
        "        continue\n",
        "    train_df = df_train_split[available]\n",
        "    val_df = df_val_split[available]\n",
        "    train_inputs, val_inputs = build_inputs(train_df, val_df)\n",
        "    results = tune_model(model_path, train_inputs, val_inputs, val_df)\n",
        "    top_categories[category] = top_k(results, k=3)\n",
        "\n",
        "summary = {\n",
        "    'general': top_general,\n",
        "    'categories': top_categories,\n",
        "}\n",
        "Path('top_configs.json').write_text(json.dumps(summary, indent=2), encoding='utf-8')\n",
        "print('Saved top_configs.json')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}